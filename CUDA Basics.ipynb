{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Studnet: Jhuma kabir meem\n",
        "#Exercise Cuda basic\n",
        "# !pip install pycuda"
      ],
      "metadata": {
        "id": "6Tbj769RAjMs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- initialize the device\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import pycuda.autoinit"
      ],
      "metadata": {
        "id": "-7udhE6IO0Lf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyKLpWwIAVOd",
        "outputId": "2e5ee106-06ac-4ed2-c511-37eb7e401363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Random vectors A:\n",
            "[[-0.34502926 -0.78622866  1.0008224  -1.8360682   0.6735068 ]]\n",
            "----------\n",
            "Random vectors B:\n",
            "[[-1.1676087  -0.74887156 -1.1301663   1.1365993  -1.355186  ]]\n",
            "----------\n",
            "CUDA kernel performing elemenwise add operation of  Vector A and B:\n",
            "[[-1.512638   -1.5351002  -0.12934387 -0.69946885 -0.6816792 ]]\n",
            "----------\n",
            "CPU and GPU addition produced same result\n"
          ]
        }
      ],
      "source": [
        "###### Part 1\n",
        "# Generate two random vectors and implement CUDA kernel performing elemenwise add operation\n",
        "N = 5 # length of array\n",
        "\n",
        "# --- Create random vectors on the CPU\n",
        "A = np.random.randn(1, N)\n",
        "B = np.random.randn(1, N)\n",
        "\n",
        "# --- Set CPU arrays as single precision\n",
        "A = A.astype(np.float32)\n",
        "B = B.astype(np.float32)\n",
        "\n",
        "a = gpuarray.to_gpu(A)\n",
        "b = gpuarray.to_gpu(B)\n",
        "add_a_b = gpuarray.empty_like(a)\n",
        "\n",
        "\n",
        "from pycuda.elementwise import ElementwiseKernel\n",
        "\n",
        "# CUDA element wise add\n",
        "lin_comb = ElementwiseKernel(\n",
        "        \"float *add_a_b, float *a, float *b\",\n",
        "        \"add_a_b[i] =  a[i] + b[i]\")\n",
        "\n",
        "lin_comb(add_a_b, a, b,)\n",
        "\n",
        "# Get results from device to host\n",
        "h_c = add_a_b.get()\n",
        "\n",
        "\n",
        "print(\"-\" * 10)\n",
        "print (\"Random vectors A:\")\n",
        "print(a)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "print (\"Random vectors B:\")\n",
        "print(b)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "print (\"CUDA kernel performing elemenwise add operation of  Vector A and B:\")\n",
        "print(add_a_b)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "# Compare CPU and GPU addition result\n",
        "if np.array_equal(h_c,  A +  B):\n",
        "  print(\"CPU and GPU addition produced same result\")\n",
        "else :\n",
        "  print(\"Error!: CPU and GPU doesnot produce same result\")\n",
        "\n",
        "# --- Flush context printf buffer\n",
        "cuda.Context.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Part 2\n",
        "#Generate two random matrices and implement CUDA kernel performing matrix multiplication\n",
        "\n",
        "\n",
        "# kernel code for matrix multiplication\n",
        "\n",
        "kernel_matrix_multiplication_code = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    float P_value = 0;\n",
        "\n",
        "    for (int k = 0; k < %(m_size)s; ++k) {\n",
        "        float a_e = a[ty * %(m_size)s + k];\n",
        "        float b_e = b[k * %(m_size)s + tx];\n",
        "        P_value += a_e * b_e;\n",
        "    }\n",
        "    c[ty * %(m_size)s + tx] = P_value;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "m_size = 3 # define matrix size\n",
        "\n",
        "A = np.random.randn(m_size, m_size).astype(np.float32) # create two random square matrices\n",
        "B = np.random.randn(m_size, m_size).astype(np.float32)\n",
        "\n",
        "multiplication_cpu = np.dot(A, B) # compute cpu matrix multiplication to compare  GPU computation\n",
        "\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(A) # transfer host (CPU) memory to device (GPU) memory \n",
        "b_gpu = gpuarray.to_gpu(B)\n",
        "\n",
        "# create empty gpu array \n",
        "multiplication_gpu = gpuarray.empty((m_size, m_size), np.float32)\n",
        "\n",
        "# get the kernel code  and  by specifying matrix size\n",
        "kernel_code = kernel_matrix_multiplication_code % {\n",
        "    'm_size': m_size \n",
        "    }\n",
        "\n",
        "# compile the kernel code \n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "# get the kernel function from the compiled module\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "# call the kernel on the card\n",
        "matrixmul( a_gpu, b_gpu, multiplication_gpu, block = (m_size, m_size, 1),\n",
        "    )\n",
        "\n",
        "#print the results\n",
        "print(\"-\" * 10)\n",
        "print (\"Random Matrix A:\")\n",
        "print (a_gpu.get())\n",
        "\n",
        "print (\"-\" * 10)\n",
        "print (\"Random Matrix B:\")\n",
        "print (b_gpu.get())\n",
        "\n",
        "print (\"-\" * 10)\n",
        "print (\"Matrix multiplication of A and B (GPU):\")\n",
        "print (multiplication_gpu.get())\n",
        "\n",
        "print (\"-\" * 10)\n",
        "if np.array_equal(multiplication_cpu,  multiplication_gpu.get()):\n",
        "  print(\"CPU and GPU multuiplication  produced same result\")\n",
        "else :\n",
        "  print(\"Error!: CPU and GPU does not produce same result\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUc_1yicPK7I",
        "outputId": "cffcedb9-60ad-4c1e-b27b-3e33851e3571"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Random Matrix A:\n",
            "[[ 1.6640799  -0.06716456 -1.5063071 ]\n",
            " [-0.25112775  0.11923535 -0.23239048]\n",
            " [-0.79191923 -0.47793746  1.6814418 ]]\n",
            "----------\n",
            "Random Matrix B:\n",
            "[[-0.08376075 -1.3749142  -1.5821311 ]\n",
            " [ 1.0775951  -0.25780284  0.0922598 ]\n",
            " [-0.57076025 -1.181374    0.9831074 ]]\n",
            "----------\n",
            "Matrix multiplication of A and B (GPU):\n",
            "[[ 0.64797944 -0.4911398  -4.1198506 ]\n",
            " [ 0.28216133  0.5890799   0.17985286]\n",
            " [-1.4083915  -0.7743769   2.8618634 ]]\n",
            "----------\n",
            "CPU and GPU multuiplication  produced same result\n"
          ]
        }
      ]
    }
  ]
}